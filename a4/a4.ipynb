{"cells":[{"cell_type":"code","execution_count":18,"id":"7fac7490","metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.regression import DecisionTreeRegressor\n","from pyspark.ml import Pipeline\n","from pyspark.ml.evaluation import RegressionEvaluator"]},{"cell_type":"code","execution_count":2,"id":"80f9d0aa","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["25/04/26 07:30:54 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n","                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------+\n","|passenger_count|pulocationid|dolocationid|total_amount|\n","+---------------+------------+------------+------------+\n","|            1.0|       151.0|       239.0|        9.95|\n","|            1.0|       239.0|       246.0|        16.3|\n","|            3.0|       236.0|       236.0|         5.8|\n","|            5.0|       193.0|       193.0|        7.55|\n","|            5.0|       193.0|       193.0|       55.55|\n","|            5.0|       193.0|       193.0|       13.31|\n","|            5.0|       193.0|       193.0|       55.55|\n","|            1.0|       163.0|       229.0|        9.05|\n","|            1.0|       229.0|         7.0|        18.5|\n","|            2.0|       141.0|       234.0|        13.0|\n","+---------------+------------+------------+------------+\n","only showing top 10 rows\n","\n"]}],"source":["# 1.  dataset that only contains passenger_count (4th col), pulocationid (8th col), dolocationid (9th col), \n","#     and total_amount (17th col) based on the 2019-01-h1.csv dataset\n","\n","spark = SparkSession.builder.appName(\"SparkA4\").getOrCreate()\n","csv_file = \"gs://dataproc-staging-us-central1-823943063357-inh6zdl6/data/2019-01-h1.csv\"\n","df = spark.read.csv(csv_file, \n","                    header=True, \n","                    inferSchema=True)\n","df.select(\"passenger_count\", \"pulocationid\", \"dolocationid\", \"total_amount\").show(10)"]},{"cell_type":"code","execution_count":3,"id":"6d33d057","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 6:============================================>              (3 + 1) / 4]\r"]},{"name":"stdout","output_type":"stream","text":["There are 2920930 rows in the training set, and 730150 in the test set\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["# 2. Create trainDF and testDF\n","trainDF, testDF = df.randomSplit([.8, .2], seed=42)\n","print(f\"\"\"There are {trainDF.count()} rows in the training set, and {testDF.count()} in the test set\"\"\")"]},{"cell_type":"code","execution_count":10,"id":"1857e690","metadata":{"scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\r","[Stage 12:>                                                         (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------+-----------------+\n","|passenger_count|pulocationid|dolocationid|total_amount|         features|\n","+---------------+------------+------------+------------+-----------------+\n","|            1.0|        80.0|       112.0|         6.3| [1.0,80.0,112.0]|\n","|            1.0|       114.0|        79.0|       32.75| [1.0,114.0,79.0]|\n","|            1.0|        50.0|       226.0|        25.3| [1.0,50.0,226.0]|\n","|            1.0|       249.0|         4.0|         9.8|  [1.0,249.0,4.0]|\n","|            1.0|       158.0|       158.0|         5.8|[1.0,158.0,158.0]|\n","|            1.0|       246.0|        68.0|         7.8| [1.0,246.0,68.0]|\n","|            1.0|       164.0|       224.0|        10.8|[1.0,164.0,224.0]|\n","|            1.0|       226.0|       129.0|        55.3|[1.0,226.0,129.0]|\n","|            1.0|       142.0|       260.0|        17.3|[1.0,142.0,260.0]|\n","|            1.0|       141.0|       133.0|        40.0|[1.0,141.0,133.0]|\n","+---------------+------------+------------+------------+-----------------+\n","only showing top 10 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["# 3. Create a decision tree regressor to predict total_amount from the other three features\n","\n","vecAssembler = VectorAssembler(inputCols=[\"passenger_count\", \"pulocationid\", \"dolocationid\"], outputCol=\"features\")\n","vecTrainDF = vecAssembler.transform(trainDF)\n","vecTrainDF.select(\"passenger_count\", \"pulocationid\", \"dolocationid\", \"total_amount\", \"features\").show(10)\n","\n","decisiontree = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"total_amount\", maxBins=100)"]},{"cell_type":"code","execution_count":12,"id":"2a53908a","metadata":{},"outputs":[],"source":["# 4. Create a pipeline\n","\n","pipeline = Pipeline(stages=[vecAssembler, decisiontree])"]},{"cell_type":"code","execution_count":15,"id":"7d6fb1ce","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# 5. Train the model\n","\n","model = pipeline.fit(trainDF)"]},{"cell_type":"code","execution_count":17,"id":"e6e50be3","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\r","[Stage 42:>                                                         (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------+------------------+\n","|passenger_count|pulocationid|dolocationid|total_amount|        prediction|\n","+---------------+------------+------------+------------+------------------+\n","|            1.0|       223.0|       223.0|         4.3|11.704727838091687|\n","|            1.0|       234.0|       186.0|         6.2|11.704727838091687|\n","|            1.0|       158.0|       249.0|         5.8|13.307442852646982|\n","|            1.0|       140.0|       237.0|        10.3|11.704727838091687|\n","|            1.0|       148.0|        79.0|         8.8|15.790206564690084|\n","|            1.0|       233.0|       198.0|        27.3|11.704727838091687|\n","|            1.0|       158.0|       164.0|        14.8|11.704727838091687|\n","|            4.0|       161.0|       229.0|         6.8|11.704727838091687|\n","|            1.0|       143.0|       262.0|        15.3|13.307442852646982|\n","|            3.0|        37.0|        36.0|         7.3| 19.13224138340017|\n","+---------------+------------+------------+------------+------------------+\n","only showing top 10 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["# 6. Show the predicted results along with the three features in the notebook\n","\n","prediction = model.transform(testDF)\n","prediction.select(\"passenger_count\", \"pulocationid\", \"dolocationid\", \"total_amount\", \"prediction\").show(10)"]},{"cell_type":"code","execution_count":20,"id":"4bd1953c","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 44:===========================================>              (3 + 1) / 4]\r"]},{"name":"stdout","output_type":"stream","text":["RMSE value: 72.08322863719988\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["# 7. Evaluate the model with RMSE\n","regressionEvaluator = RegressionEvaluator(\n","    labelCol=\"total_amount\", \n","    predictionCol=\"prediction\", \n","    metricName=\"rmse\")\n","\n","rmse = regressionEvaluator.evaluate(prediction)\n","print(f\"RMSE value: {rmse}\")"]},{"cell_type":"code","execution_count":null,"id":"7d4a782a","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}